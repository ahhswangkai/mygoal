# 定时爬取任务使用说明

## 功能介绍

`scheduler_task.py` 是一个定时任务脚本，用于自动爬取7月1日至今的所有足球比赛数据和赔率。

## 核心特性

- **日期范围**: 自动爬取当年7月1日到当前日期的所有数据
- **定时执行**: 每天凌晨2点自动运行
- **并发爬取**: 使用8线程并发爬取赔率，提高效率
- **数据持久化**: 自动写入本地MongoDB数据库
- **首次立即执行**: 启动后立即执行一次完整爬取

## 使用方法

### 1. 安装依赖

```bash
pip install APScheduler==3.10.4
```

或使用项目依赖文件：

```bash
pip install -r requirements.txt
```

### 2. 确保MongoDB运行

确保本地MongoDB服务已启动（默认端口27017）

```bash
# macOS
brew services start mongodb-community

# 或检查状态
brew services list | grep mongodb
```

### 3. 启动定时任务

```bash
python3 scheduler_task.py
```

### 4. 查看日志

脚本运行时会实时输出日志：
- 每个日期的爬取进度
- 比赛数量与赔率写入统计
- 并发任务完成情况

### 5. 停止任务

按 `Ctrl+C` 停止定时任务

## 任务逻辑

1. **启动时立即执行**
   - 爬取2025年7月1日到当前日期的所有数据
   - 每天一次请求获取比赛列表
   - 并发爬取每场比赛的欧赔、亚盘、大小球

2. **定时调度**
   - 每天凌晨2点自动执行
   - 重新爬取7月1日至当前日期的数据
   - 已存在的数据会被更新（upsert机制）

3. **数据存储**
   - 比赛数据存入 `matches` 集合
   - 赔率数据存入 `odds` 集合
   - 赔率关键字段同步扁平化到 `matches`

## 日志输出示例

```
============================================================
定时爬取任务启动
============================================================
立即执行首次爬取...
触发定时任务: 爬取7月份以来的数据
============================================================
开始定时爬取任务: 2025-07-01 到 2025-12-02
============================================================
已连接MongoDB

>>> 爬取日期: 2025-07-01
  获取到 45 场比赛
  已写入 45 场比赛到MongoDB
  开始爬取赔率（并发数: 8）
  进度: 10/45
  进度: 20/45
  ...
  完成赔率爬取: 45/45

>>> 爬取日期: 2025-07-02
  ...

============================================================
定时任务完成！
总比赛数: 5432
总赔率数: 5401
============================================================
定时任务已设置: 每天凌晨2点执行
按 Ctrl+C 停止任务
```

## 注意事项

1. **首次运行时间较长**: 爬取7月至今约150天的数据，预计需要数小时
2. **网络稳定性**: 建议在稳定网络环境下运行
3. **MongoDB空间**: 确保有足够的磁盘空间存储数据
4. **反爬限制**: 已内置延迟与随机UA，避免过快请求

## 自定义配置

### 修改定时时间

编辑 `scheduler_task.py` 的 `main()` 函数：

```python
# 修改为每天上午10点执行
scheduler.add_job(
    crawl_july_to_now,
    CronTrigger(hour=10, minute=0),  # 改为10点
    id='daily_crawl',
    name='每日爬取7月以来数据',
    replace_existing=True
)
```

### 修改日期范围

编辑 `crawl_july_to_now()` 函数：

```python
# 改为6月1日开始
start_date = datetime(current_year, 6, 1)
```

### 修改并发数

编辑 `crawl_date_range()` 函数中的线程池：

```python
# 改为16线程并发
with ThreadPoolExecutor(max_workers=16) as executor:
```

## 后台运行（可选）

使用 `nohup` 后台运行：

```bash
nohup python3 scheduler_task.py > scheduler.log 2>&1 &
```

查看日志：

```bash
tail -f scheduler.log
```

停止后台任务：

```bash
ps aux | grep scheduler_task.py
kill <进程ID>
```

## 与Web服务配合

定时任务会持续更新MongoDB数据，Web服务（`web_app.py`）会实时读取最新数据。无需重启Web服务即可看到新数据。
