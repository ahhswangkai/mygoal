# 快速开始指南 🚀

欢迎使用足彩爬虫工具！本指南将帮助您快速上手。

## 📋 目录结构

```
football-crawler/
├── 📄 核心文件
│   ├── config.py          # 配置管理
│   ├── crawler.py         # 爬虫引擎
│   ├── storage.py         # 数据存储
│   ├── utils.py           # 工具函数
│   └── main.py            # 主程序
│
├── 📚 文档
│   ├── README.md          # 项目说明
│   ├── USAGE.md           # 详细使用指南
│   ├── PROJECT_OVERVIEW.md # 项目概览
│   └── 快速开始.md        # 本文件
│
├── 🔧 配置与脚本
│   ├── requirements.txt   # 依赖包
│   ├── .env.example       # 环境变量示例
│   ├── quickstart.sh      # 一键启动脚本
│   └── example.py         # 使用示例
│
└── 📁 数据目录
    ├── data/              # 爬取数据存储
    └── logs/              # 日志文件
```

## ⚡ 三步快速开始

### 第一步：安装环境

```bash
# 进入项目目录
cd football-crawler

# 一键安装（推荐）
./quickstart.sh
```

### 第二步：测试功能

```bash
# 激活虚拟环境（如果quickstart.sh已运行，跳过此步）
source venv/bin/activate

# 运行示例代码（使用模拟数据测试）
python example.py

# 选择选项 3：测试数据导出功能
```

### 第三步：实际使用

**⚠️ 重要：在实际使用前，需要根据目标网站修改解析规则！**

```bash
# 修改 crawler.py 中的解析方法后再运行
python main.py --site 500wan --format csv
```

## 🎯 修改解析规则（必读）

由于每个网站的HTML结构不同，您需要自定义解析规则：

### 1. 打开目标网站

```bash
# 例如：访问 https://live.500.com/
```

### 2. 查看HTML结构

1. 按 `F12` 打开浏览器开发者工具
2. 点击 "Elements" 或 "元素" 标签
3. 找到比赛列表的HTML结构
4. 记下关键的class名称或id

### 3. 修改解析代码

编辑 `crawler.py` 文件：

```python
def parse_match_list(self, html_content):
    """解析比赛列表 - 需要根据实际网站修改"""
    soup = BeautifulSoup(html_content, 'lxml')
    matches = []
    
    # ⚠️ 修改这里的选择器
    match_items = soup.find_all('div', class_='实际的class名称')
    
    for item in match_items:
        match_data = {
            # ⚠️ 修改这里的字段提取逻辑
            'match_id': item.get('data-id', ''),
            'league': item.find('span', class_='实际的class').text.strip(),
            # ... 其他字段
        }
        matches.append(match_data)
    
    return matches
```

### 4. 测试修改

```bash
# 运行并查看日志
python main.py --site 500wan --format json

# 查看日志文件
tail -f logs/crawler.log
```

## 💡 使用示例

### 示例1：爬取并保存为CSV

```bash
python main.py --site 500wan --format csv
```

**输出**：
```
==================================================
开始爬取足彩数据
目标网站: 500wan
保存格式: csv
==================================================

>>> 步骤1: 爬取每日比赛列表
成功获取 25 场比赛信息

>>> 步骤2: 爬取比赛赔率数据
[1/5] 爬取比赛 12345 的赔率
获取到 8 条赔率数据
...

>>> 步骤3: 保存组合数据
==================================================
爬取完成！
比赛数据: ./data/matches_20251130_220000.csv
组合数据: ./data/combined_20251130_220000.csv
==================================================
```

### 示例2：爬取并保存为JSON

```bash
python main.py --site zgzcw --format json
```

### 示例3：仅爬取比赛列表（不爬赔率）

修改 `main.py` 中的代码，注释掉赔率爬取部分。

## 📊 查看爬取的数据

### CSV格式

```bash
# 使用Excel或任何文本编辑器打开
open data/matches_*.csv
```

### JSON格式

```bash
# 查看JSON文件内容
cat data/matches_*.json | python3 -m json.tool
```

### Excel格式

```bash
# 直接用Excel打开
open data/matches_*.xlsx
```

## 🔧 常用配置修改

### 1. 修改请求延迟（避免被封）

编辑 `config.py`:

```python
REQUEST_DELAY = 5  # 改为5秒延迟
```

### 2. 修改重试次数

```python
MAX_RETRIES = 5  # 增加重试次数
```

### 3. 添加新的目标网站

```python
TARGET_URLS = {
    '500wan': 'https://live.500.com/',
    'zgzcw': 'https://www.zgzcw.com/',
    'okooo': 'https://www.okooo.com/',
    'my_site': 'https://my-football-site.com/',  # 添加新网站
}
```

## ⏰ 设置定时爬取

### Mac/Linux

```bash
# 编辑crontab
crontab -e

# 添加定时任务（每天早上8点执行）
0 8 * * * cd /Users/kai/workspace/AI/football-crawler && /Users/kai/workspace/AI/football-crawler/venv/bin/python main.py --format csv
```

### Windows

1. 打开"任务计划程序"
2. 创建基本任务
3. 设置触发器：每天 08:00
4. 操作：启动程序
   - 程序：`C:\...\venv\Scripts\python.exe`
   - 参数：`main.py --format csv`
   - 起始于：项目目录

## 🐛 遇到问题？

### 问题1：安装依赖失败

```bash
# 升级pip
pip install --upgrade pip

# 使用国内镜像源
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 问题2：无法获取数据

**检查清单**：
1. ✅ 网站URL是否正确？
2. ✅ 网络连接是否正常？
3. ✅ 解析规则是否匹配网站结构？
4. ✅ 查看日志文件 `logs/crawler.log`

```bash
# 查看最新日志
tail -20 logs/crawler.log
```

### 问题3：数据格式不对

**解决方法**：
1. 查看示例数据格式
2. 确认解析字段名称正确
3. 使用example.py测试

### 问题4：被网站封禁

**解决方法**：
1. 增加 `REQUEST_DELAY` 参数
2. 减少爬取数量
3. 更换IP地址

## 📚 下一步学习

1. **阅读完整文档**
   - `README.md` - 项目概述
   - `USAGE.md` - 详细使用指南
   - `PROJECT_OVERVIEW.md` - 技术架构

2. **查看示例代码**
   - `example.py` - 包含3个实用示例

3. **自定义功能**
   - 添加数据库存储
   - 实现数据分析
   - 开发Web界面

## 🎉 成功案例

成功爬取后，您将得到：

```
data/
├── matches_20251130_220000.csv         # 比赛列表
├── combined_20251130_220000.csv        # 比赛+赔率
└── demo_matches_20251130_223100.json   # 演示数据
```

数据可用于：
- 📊 数据分析和可视化
- 🤖 机器学习预测模型
- 📈 赔率趋势分析
- 🎯 投注策略研究

## ⚠️ 重要提醒

1. **合法使用**：仅用于学习研究，禁止商业用途
2. **尊重网站**：遵守robots.txt，合理控制频率
3. **数据安全**：不要泄露个人敏感信息
4. **及时维护**：网站结构变化时更新代码

## 📞 需要帮助？

- 查看日志文件：`logs/crawler.log`
- 阅读详细文档：`USAGE.md`
- 运行测试示例：`example.py`

---

**祝您使用愉快！** 🎊

如有问题，请查看文档或提交Issue。
